# Statistics

## Counts 

Spotlight count: 8

Poster count: 52

Oral count: 6

Total count: 66

## Keywords

reinforcement learning:45

robotics:6

deep reinforcement learning:5

exploration:5

imitation learning:3

reward learning:3

meta-learning:3

model-based reinforcement learning:3

deep learning:3

planning:3

goal reaching:3

Multi-agent reinforcement learning:2

model predictive control:2

autonomous learning:2

contrastive learning:2

benchmarks:2

natural language processing:2

communication:2

optimization:2

multi-task reinforcement learning:2

batch reinforcement learning:2

safe:2

multi-agent reinforcement learning:2

computer vision:2

representation learning:2

offline reinforcement learning:2

Q-learning:2

generalization:2

domain adaptation:2

transfer learning:2

function approximation:2

delay:1

task reduction:1

sparse reward:1

compositional task:1

attention:1

intention:1

distance:1

irl:1

rl:1

distance metric learning:1

meta-reinforcement learning:1

offline/batch reinforcement learning:1

visual reinforcement learning:1

object-centric representations:1

self-supervision:1

lifelong:1

reset-free:1

simulation:1

relaxed regularization:1

continuation method:1

model-based control:1

off-line reinforcement learning:1

Dueling structure:1

Value factorization:1

human-computer interaction:1

meta learning:1

model-based learning:1

policy learning:1

zero-order optimization:1

symbolic representations:1

intrinsic motivations:1

Deep reinforcement learning:1

DNN:1

augmented deep reinforcement learning:1

mixed precision:1

Quantization:1

Reinforcement Learning:1

Imitation Learning:1

Inverse reinforcement learning:1

Bayesian:1

auxiliary task:1

Information theory:1

Unsupervised reinforcement learning:1

off-policy RL:1

experience replay buffer:1

interactive fiction:1

Monte-Carlo tree search:1

safety:1

robust:1

risk sensitive:1

risk-averse:1

offline:1

task generation:1

procedural generation:1

curriculum learning:1

goal-conditioned reinforcement learning:1

multi-task learning:1

model based reinforcement learning:1

off-policy evaluation:1

compositionality:1

human cognition:1

genetic programming:1

evolutionary algorithms:1

covariant neural networks:1

molecular design:1

robotic manipulation:1

plan-based reward shaping:1

reward shaping:1

graph neural network:1

power grid management:1

Frobenius norm:1

Kullback-Leibler divergence:1

Wasserstein distance:1

projection:1

policy gradient:1

trust region:1

unsupervised learning:1

variational inference:1

relabelling:1

experience replay:1

differentiable optimization:1

robust control:1

heteroscedasticity:1

dynamic systems:1

mixture density nets:1

generative models:1

model-predictive control:1

regularized markov decision processes:1

inverse reinforcement learning:1

block mdp:1

hidden-parameter mdp:1

bisimulation:1

policy optimization:1

autoregressive models:1

Off-policy policy evaluation:1

game theory:1

no-regret learning:1

regret minimization:1

multi-agent systems:1

representation:1

lower bound:1

adversarial attack:1

black-box attack:1

hard-label attack:1

control barrier function:1

Multi-agent:1

unsupervised skill discovery:1

options:1

hierarchical reinforcement learning:1

diverse strategies:1

reward randomization:1

strategic behavior:1

sim2real:1

self-supervised learning:1

learning theory:1

constrained RL:1

factored MDP:1

actor critic:1

world models:1

Atari:1

learning action representations:1

multi-dimensional discrete action spaces:1

structural inductive bias:1

structural credit assignment:1

constraints:1

meta-gradients:1

adversarial defense:1

adversarial attacks:1

robustness:1

distance learning:1

model learning:1

hindsight relabeling:1

density estimation:1

causality:1

sim2real transfer:1

automated machine learning:1

symbolic regression:1

goal-conditioned RL:1

behavior cloning:1

provable sample efficiency:1

regret analysis:1

theory:1

optimism:1

